FastAPI 웹 챗봇을 Render에 배포하는 방법


프로젝트 준비 (필수 파일)

(1) app.py 예시 (FastAPI 챗봇 뼈대)
아래는 “동작 확인용” 최소 예시이다. OpenAI 호출은 본인 코드로 바꾸면 된다.

from fastapi import FastAPI
from pydantic import BaseModel
import os

app = FastAPI()

class ChatReq(BaseModel):
    message: str

@app.get("/")
def health():
    return {"ok": True}

@app.post("/chat")
def chat(req: ChatReq):
    # 실제로는 OpenAI API 호출로 답변 생성하도록 구현
    return {"reply": f"you said: {req.message}"}


(2) requirements.txt 예시
FastAPI는 ASGI 서버(uvicorn 또는 gunicorn+uvicorn worker)가 필요하다.

가장 단순한 구성(uvicorn 직접 실행):

fastapi==0.110.0
uvicorn[standard]==0.27.1
openai>=1.5.0


운영형 구성(권장: gunicorn + uvicorn worker):
Render도 운영 배포에서는 보통 gunicorn+uvicorn worker 조합을 안내/권장한다.

fastapi==0.110.0
gunicorn==22.0.0
uvicorn[standard]==0.27.1
openai>=1.5.0


Render에서 Web Service 생성

(1) Render 대시보드에서 New + → Web Service
(2) GitHub 레포 연결
(3) Runtime은 Python(Web Service)로 생성

Build Command / Start Command 설정 (핵심)

Render Web Service는 외부 트래픽을 단일 포트로 포워딩하며, 서버는 PORT 환경변수에 바인딩해야 한다. 기본 PORT는 10000이다.

A안: uvicorn 직접 실행(가장 단순)
Start Command:

uvicorn app:app --host 0.0.0.0 --port $PORT


이 형태는 여러 예제에서 그대로 사용한다.

B안: gunicorn + uvicorn worker(운영 권장)
Start Command:

gunicorn main:app -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:$PORT


gunicorn+UvicornWorker는 Uvicorn 문서에서도 대표적인 운영 실행 방식이다.

Build Command는 보통 기본값(Automatically: pip install -r requirements.txt)로 충분하다.

환경변수 설정 (OpenAI 키 등)

Render 대시보드 → Environment에서
OPENAI_API_KEY 같은 값을 등록한다.
Render는 환경변수/시크릿 설정을 권장한다.

배포 후 확인

(1) 배포 로그에서 “포트 오픈 감지”가 되어야 정상이다.
“No open ports detected”가 나오면 0.0.0.0 바인딩과 $PORT 사용을 다시 점검한다.

(2) 접속 테스트

GET / 로 헬스체크

POST /chat 로 응답 확인

웹 챗봇 UI까지 같이 만들려면

FastAPI는 API 서버이다.
브라우저에서 “채팅 화면(UI)”까지 한 서비스로 만들려면 보통 둘 중 하나를 선택한다.

FastAPI + 템플릿(Jinja2) + JS(fetch)로 단일 서비스 구성

Streamlit을 프론트로 두고, FastAPI를 백엔드로 분리(멀티 서비스)

원하는 방식(단일 서비스인지, UI도 같이인지)을 말해주면 그 구조로 폴더 구성, 코드, Render 설정까지 한 번에 정리해 준다.